{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Big Data &ndash; Moodle Exercises </center>\n",
    "## <center>Fall 2025 &ndash; Week 9 &ndash; ETH Zurich</center>\n",
    "## <center>Spark Dataframes and Spark SQL, Moodle exercise</center>\n",
    "\n",
    "# Preparation for the moodle exercise in Spark\n",
    "\n",
    "In this jupyter notebook we are going to make the preprocessing part of the dataset that is going to be used in the graded exercise of this week. It will be the same language game dataset as seen in the exercises. If you still do not have created the `confusion-part.json` file, follow these instruction. If you only have it in the `exercise08` folder please copy the `confusion-2014-03-02` folder in the `notebooks` folder of your exam magic box.\n",
    "\n",
    "1. Move to the `notebooks` folder of the magicbox in the terminal\n",
    "2. Download the data <br>\n",
    "   ```bash\n",
    "   wget https://f003.backblazeb2.com/file/larsyencken-eu-public/greatlanguagegame/confusion-2014-03-02.tbz2\n",
    "   # or\n",
    "   curl -O https://f003.backblazeb2.com/file/larsyencken-eu-public/greatlanguagegame/confusion-2014-03-02.tbz2\n",
    "   ```\n",
    "3. Extract the data <br>\n",
    "   ```bash\n",
    "   tar -jxvf confusion-2014-03-02.tbz2\n",
    "   ```\n",
    "4. Change directory to extracted folder <br> \n",
    "   ```bash\n",
    "   cd confusion-2014-03-02/\n",
    "   ```\n",
    "5. Extract the part of the dataset that we will work with in this exercise <br>\n",
    "   ```bash\n",
    "   head -n 3000000 confusion-2014-03-02.json > confusion-part.json\n",
    "   ```\n",
    "## More Info about the data\n",
    "You can find more information about the dataset (as well as the schema and examples) in the `README.md` file inside the data bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "In every query we ask you for three quantities: \n",
    "- the query itself,\n",
    "- the result of the query,\n",
    "- the productivity time - the development time of each query (time elapsed from before you start writing the query, until the time at which the correct, final query is ready).\n",
    "\n",
    "Note that the time part of every question is optional and not graded. In order to make easier the time recording we created two functions that do it automatically. Run the cell below in order to import the functions into the current notebook. Then before each query we will have a ```start_exercise()``` cell that you have to run in order to start time recording. After you have finished your query and you are sure about the answer run the ```finish_exercise()``` one to get the time measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 39.236083984375,
      "end_time": 1573672504782.379
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def start_exercise():\n",
    "    global last\n",
    "    last = time.time()\n",
    "    \n",
    "def finish_exercise():\n",
    "    global last\n",
    "    print(\"This exercise took {0}s\".format(int(time.time()-last)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Spark Dataframes and SparkSQL</center>\n",
    "\n",
    "Write queries for the same dataset as last week, but this time using Spark Dataframes or SparkSQL operations (the data loading will take a couple minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 11301.424072265625,
      "end_time": 1573676870300.81
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "path = \"confusion-2014-03-02/confusion-part.json\"\n",
    "dataset = spark.read.json(path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 247.257080078125,
      "end_time": 1573676894196.787
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#test it out\n",
    "dataset.limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the SparkSQL magic extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sparksql-magic --quiet\n",
    "%load_ext sparksql_magic\n",
    "dataset.createOrReplaceTempView(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "-- test it out\n",
    "SELECT *\n",
    "FROM dataset\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "\n",
    "Which language was most often wrongly guessed instead of German?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 951.284912109375,
      "end_time": 1573677112003.169
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "Find the language with the third-highest guessed percentage among all countries whose country codes contain the letter ‘S’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "\n",
    "In which month and year were the most games played?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 757.619140625,
      "end_time": 1573677388481.756
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "\n",
    "Focus on the first playing day of August 2013. Which language had the worst accuracy?\n",
    "\n",
    "(In case of a tie, return the language with more games played.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1262.1181640625,
      "end_time": 1573677845774.178
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "\n",
    "Return number of games where the guessed language is correct and it appeared last in the choices list.\n",
    "\n",
    "Hint: Check the docs of function [`element_at`](https://spark.apache.org/docs/4.0.0/api/python/reference/pyspark.sql/api/pyspark.sql.functions.element_at.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 747.340087890625,
      "end_time": 1573678219912.345
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "\n",
    "Return the language choice that was offered in the most games. How many times did it appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_exercise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
