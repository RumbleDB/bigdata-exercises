{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Big Data &ndash; Exercises &ndash; Solution</center>\n",
    "## <center>Fall 2020 &ndash; Week 3 &ndash; ETH Zurich</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This week we will cover mostly theoretical aspects of Hadoop and HDFS and we will discuss advantages and limitations of different storage models.\n",
    "\n",
    "#### What is Hadoop?\n",
    "Hadoop provides a **distributed file system** and a\n",
    "**framework for the analysis and transformation** of very **large**\n",
    "data sets using the MapReduce paradigm.\n",
    "\n",
    "Several components are part of this framework. In this course you will study HDFS, MapReduce and HBase while this exercise focuses on HDFS and storage models.\n",
    "\n",
    "\n",
    "| *Component*                |*Description*  |*First developer*  |\n",
    "|----------------------------------------------|---|---|\n",
    "| **HDFS**                  |Distributed file system  |Yahoo!  |\n",
    "| **MapReduce**   |Distributed computation framework   |Yahoo!  |\n",
    "| **HBase**           | Column-oriented table service  |Powerset (Microsoft)  |\n",
    "| Pig  | Dataflow language and parallel execution framework  |Yahoo!   |\n",
    "| Hive            |Data warehouse infrastructure   |Facebook  |\n",
    "| ZooKeeper    |Distributed coordination service   |Yahoo!  |\n",
    "| Chukwa  |System for collecting management data   |Yahoo!  |\n",
    "| Avro                |Data serialization system   |Yahoo! + Cloudera  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Hadoop Distributed File System\n",
    "### 1.1 &ndash; State which of the following statements are true:\n",
    "\n",
    "1. The HDFS namespace is a hierarchy of files and directories.\n",
    "\n",
    "1. In HDFS, each block of the file is either 64 or 128 megabytes depending on the version and distribution of Hadoop in use, and this cannot be changed.\n",
    "\n",
    "1. A client wanting to write a file into HDFS, first contacts the NameNode, then sends the data to it. The NameNode will write the data into multiple DataNodes in a pipelined fashion. \n",
    "\n",
    "1. A DataNode may execute multiple application tasks for different clients concurrently.\n",
    "\n",
    "1. The cluster can have thousands of DataNodes and tens of thousands of HDFS clients per cluster.\n",
    "\n",
    "1. HDFS NameNodes keep the namespace in RAM.\n",
    "\n",
    "1. The locations of block replicas are part of the persistent checkpoint that the NameNode stores in its native file system.\n",
    "\n",
    "1. If the block size is set to 64 megabytes, storing a file of 80 megabytes will actually require 128 megabytes of physical memory (2 blocks of 64 megabytes each). \n",
    "\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. True, in contrast with the Object Storage logic model, HDFS is designed to handle a relatively small amount of huge files. A hierarchical file system can therefore be handled efficiently by a single NameNode.\n",
    "\n",
    "1. False, the default size is either 64 or 128 megabytes but this can be easily changed in the configuration.\n",
    "\n",
    "1. False, the client writes data to the DataNodes. No data goes through the NameNode.\n",
    "\n",
    "1. True, each DataNode may execute multiple application tasks concurrently.\n",
    "\n",
    "1. True, since each DataNode can execute multiple tasks concurrently, there may be more clients than DataNodes.\n",
    "\n",
    "1. True, and an image of such namespace is also persisted in the NameNode file system.\n",
    "\n",
    "1. False, the locations of block replicas may change over time and are not part of the persistent checkpoint.\n",
    "\n",
    "1. False, the size of the data file equals the actual length of the block and does not require extra space to round it up to the nominal block size as in traditional file systems. Therefore 80 megabytes will be stored as a block of 64 megabytes + a block of 16 megabytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 &ndash; A typical filesystem block size is 4096 bytes. How large is a block in HDFS? List at least two advantages of such choice.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Typical size for a block is either 64 or 128 megabytes. A large chunk size offers several important advantages. \n",
    "\n",
    "0. it minimizes the cost of seeks. If the block is large enough, the time it takes to transfer the data from the disk can be significantly longer than the time to seek to the start of the block. Thus, transferring a large file made of multiple blocks operates at the disk transfer rate.\n",
    "\n",
    "1. it reduces clients' need to interact with the master because reads and writes on the same chunk require only one initial request to the master for chunk location information. The reduction is especially significant for our workloads because applications mostly read and write large files sequentially. \n",
    "\n",
    "2. since on a large chunk, a client is more likely to perform many operations on a given chunk, it can reduce network overhead by keeping a persistent TCP connection to the chunkserver over an extended period of time. \n",
    "\n",
    "3. it reduces the size of the metadata stored on the master. This allows us to keep the metadata in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 &ndash; How does the hardware cost grow as function of the amount of data we need to store in a Distributed File System such as HDFS? Why?\n",
    "\n",
    "\n",
    "**Solution**\n",
    "\n",
    "**Linearly**. HDFS is designed taking machine failure into account, and therefore DataNodes do not need to be (highly expensive) highly reliable machines. Instead standard commodity hardware can be used. Moreover the number of nodes can be increased as soon as it becomes necessary, avoiding wasting of resources when the amount of data is still limited. This is indeed the main advantage of scaling out compared to scaling up, which has exponential cost growth.\n",
    "\n",
    "\n",
    "### 1.4 &ndash; Single Point of Failure\n",
    "\n",
    "1. Which component is the main single point of failure in Hadoop?\n",
    "\n",
    "1. What is the Secondary NameNode?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "\n",
    "1. Prior to Hadoop 2.0.0, the **NameNode was a single point of failure**. While the loss of any other machine (intermittently or permanently) does not result in data loss, NameNode loss results in cluster unavailability. The permanent loss of NameNode data would render the cluster's HDFS inoperable.\n",
    "The HDFS High Availability feature addresses the above problems by providing the option of running two redundant NameNodes in the same cluster in an Active/Passive configuration with a hot standby. \n",
    "\n",
    "1. The Secondary NameNode is a node that merges the fsimage and the edits log files periodically and keeps edits log size within a limit. This allows the NameNode to start up faster in case of failure, but the Secondary NameNode is not a redundant NameNode. Over the years, the HDFS team kept improving on the \"alternative\" name nodes and came up almost every year with a new name with new functionality improving on the former ones. In the lecture, we discuss the latest up-to-date variant, standby namenodes, saying all the others (secondary, checkpoint, backup...) are just \"HDFS archeology\". For the possible configurations of namenodes, see [the official HDFS user guide](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Secondary_NameNode). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 &ndash; Scalability, Durability and Performance on HDFS\n",
    "Explain how HDFS accomplishes the following requirements:\n",
    "\n",
    "1. Scalability\n",
    "\n",
    "1. Durability\n",
    "\n",
    "1. High sequential read/write performance\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. Scalability: by partitioning files into blocks and distributing them to many servers operating in parallel, HDFS can scale to potentially a large number of files of any size. By adding more DataNodes the storage capacity of the system can be increased arbitrarily. It has been demonstrated to scale beyond tens of petabytes (PB). More importantly, it does so with linear performance characteristics and cost.\n",
    "\n",
    "1. Durability: HDFS creates multiple copies of each block (by default 3, on different racks) to minimize the probability of data loss.\n",
    "\n",
    "1. High sequential read/write performance: by splitting huge files into blocks and spreading these into multiple machines. This makes parallel reads possible (accessing different nodes at the same time) either by using multiple clients or by using a distributed data processing framework such as MapReduce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File I/O operations and replica management.\n",
    "\n",
    "\n",
    "### 2.1 &ndash; Replication policy\n",
    "Assume your HDFS cluster is made of 3 racks, each containing 3 DataNodes. Assume also the HDFS is configured to use a block size of 100 megabytes and that a client is connecting from outside the datacenter (therefore no DataNode is priviledged). \n",
    "\n",
    "1. The client uploads a file of 150 megabytes. Draw in the picture below a possible blocks configuration according to the default HDFS replica policy. How many replicas are there for each block? Where are these replicas stored?\n",
    "\n",
    "1. Can you find a with a different policy that, using the same number of replicas, improves the expected availability of a block? Does your solution show any drawbacks?\n",
    "\n",
    "1. Referring to the picture below, assume a block is stored in Node 3, as well as in Node 4 and Node 5. If this block of data has to be processed by a task running on Node 6, which of the three replicas will be actually read by Node 6? \n",
    "\n",
    "<img src=\"https://bigdata2020exassets.blob.core.windows.net/ex03/cluster.jpg\" width=\"500\">\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. For each block independently, the HDFS's placement policy is to put one replica on a random node in a random rack, another on one node in a different rack, and the last on a different node in the same rack chosen for the second replica. A possibile configuration is shown in the picture (but there are many more valid solutions).\n",
    "\n",
    "1. One could decide to store the 3 replicas in 3 different racks, increasing the expected availability. However this would also slow down the writing process that would involve two inter-rack communications instead of one. Usually, the probability of failure of an entire rack is much smaller than the probability of failure of a node and therefore it is a good tradeoff to have 2/3 of the replicas in one rack.\n",
    "\n",
    "1. Either the one stored in Node 4 or Node 5, assuming the intra-rack topology is such that the distance from these nodes to Node 6 is the same. In general, the reading priority is only based on the distance, not on which node was first selected in the writing process.\n",
    "\n",
    "<img src=\"https://bigdata2020exassets.blob.core.windows.net/ex03/cluster_solut.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 &ndash; File read and write data flow.\n",
    "To get an idea of how data flows between the client interacting with HDFS, consider a diagram below which shows main components of HDFS. \n",
    "\n",
    "<img src=\"https://bigdata2020exassets.blob.core.windows.net/ex03/clientHDFS.jpg\" width=\"600\">\n",
    "\n",
    "1. Draw the main sequence of events when a client copies a file to HDFS.\n",
    "2. Draw the main sequence of events when a client reads a file from HDFS.\n",
    "3. Why do you think a client writes data directly to datanodes instead of sending it through the namenode?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1 - Steps 2-5 are applied for each block of the file. <br>\n",
    "   1. HDFS client asks the Namenode to create the file.\n",
    "   2. HDFS client asks the Namenode for a DataNode to host replica of the i-th block of the file. <br>\n",
    "   3. NameNode replies with a list of DataNodes and their locations for i-th block. <br>\n",
    "   4. The client writes i-th block to DataNodes in pipeline fashion. <br>\n",
    "   5. DataNodes in the write pipeline acknowledge the writing of a block. Once all of them replied, the first contacted DataNode replies with acknowledgement to the client. <br>\n",
    "   6. The client sends to the NameNode a request to close the file and release the lock. <br>\n",
    "   7. The DataNodes check with the NameNode for minimal replication. <br>\n",
    "   8. The NameNode sends ack to the client on finishing writing the file. <br>\n",
    "\n",
    "<img src=\"https://bigdata2020exassets.blob.core.windows.net/ex03/clientHDFSsolWrite.jpg\" width=\"500\">\n",
    "\n",
    "2 -  \n",
    "   1. HDFS client request a file <br>\n",
    "   2. NameNode replies with a list of blocks and the locations of each replica. <br>\n",
    "   3. The client reads each block from the closest datanode.\n",
    "\n",
    "<img src=\"https://bigdata2020exassets.blob.core.windows.net/ex03/clientHDFSsolRead.jpg\" width=\"500\">\n",
    "\n",
    "3 - if the namenode was responsible for copying all files to datanodes. then it would become a bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 &ndash; Network topology.\n",
    "HDFS estimates the network bandwidth between two nodes by their distance. The distance from a node to its parent node is assumed to be one. A distance between two nodes can be calculated by summing up thier distances to their closest common ancestor. A shorter distance between two nodes means that the greater bandwidth they can utilize to transfer data. Consider a diagram of a possible hadoop cluster over two datacenters below. \n",
    "\n",
    "<img src=\"https://bigdata2020exassets.blob.core.windows.net/ex03/networkHDFS.jpg\" width=\"700\">\n",
    "\n",
    "Calculate following distances using the distance rule explained above:\n",
    "1. Node 0 and Node 1\n",
    "2. Node 0 and Node 2\n",
    "3. Node 1 and Node 4\n",
    "4. Node 4 and Node 5\n",
    "5. Node 2 and Node 3\n",
    "6. Two processes of Node 1\n",
    "\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. 2\n",
    "2. 4 \n",
    "3. 6\n",
    "4. 4\n",
    "5. 2\n",
    "6. 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Storage models\n",
    "### 3.1 &ndash; List two differences between Object Storage and Block Storage.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. Block Storage implements file storage API, whereas Object Storage provides only key-value interface.\n",
    "\n",
    "2. Pure Object Storage has a limit on object size, since the object cannot be partitioned across machines. Block Storage does not have this limitation and can split objects into blocks. Therefore, Block Storage can store PB files, whereas Object Storage is limited by the storage capacity of a single node. On the other hand, object storage can store more files than Block Storage.  \n",
    "\n",
    "### 3.2 &ndash; Compare Object Storage and Block Storage. For each of the following use cases, say which technology better fits the requirements.\n",
    "\n",
    "1. Store Netflix movie files in such a way they are accessible from many client applications at the same time [ *Object storage | Block Storage* ]\n",
    "\n",
    "1. Store experimental and simulation data from CERN [ *Object storage | Block Storage* ]\n",
    "\n",
    "1. Store the auto-backups of iPhone/Android devices [ *Object storage | Block Storage* ]\n",
    "\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. **Object Storage**. The movies are not excessively large to require Block Storage, while they can indefinitely in number, also a simple key-value model is enough without requiring a file-system hierarchy.\n",
    "\n",
    "1. **Block Storage**. Because it can handle large files and store more data than ordinary object storage.\n",
    "\n",
    "1. **Object Storage**. Backups are usually written once and rarely read. When data is read, partial access to each file is not essential. The client devices do not need to know the block composition of the object being stored. In fact, Apple [publicly confirmed](http://readwrite.com/2014/08/26/apple-icloud-amazon-web-services-hosting/) that backups data for iOS is stored on Amazon S3 and Microsoft Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Install Hadoop\n",
    "You can now install Hadoop on your local computer to test HDFS in practice, we are going to try the last version  `3.3.0`. The installation on GNU/Linux is rather easy, [follow this steps](https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/SingleCluster.html). With a similar procedure you can also install on [Windows](https://kontext.tech/column/hadoop/447/install-hadoop-330-on-windows-10-step-by-step-guide) \\([alternative old guide](http://wiki.apache.org/hadoop/Hadoop2OnWindows)) or [Mac OSX](https://towardsdatascience.com/installing-hadoop-on-a-mac-ec01c67b003c) \\([alternative old guide](http://zhongyaonan.com/hadoop-tutorial/setting-up-hadoop-2-6-on-mac-osx-yosemite.html)).\n",
    "\n",
    "During next recitation sessions, we will use a cluster version of HDFS on Azure. The purpose of this session is to familiarise you with shell commands and web Interface by using your local machines. \n",
    "\n",
    "Each Hadoop cluster is set up in one of the three supported modes:\n",
    "\n",
    "- Local (Standalone) Mode\n",
    "- Pseudo-Distributed Mode\n",
    "- Fully-Distributed Mode\n",
    "\n",
    "By default Hadoop runs in Local Mode but you should set-up it for **Pseudo-Distributed Mode**. This will allow you to run Hadoop on a single-node (your computer) simulating a distributed file system. As explained in the tutorials, to set up a Pseudo-Distributed Mode you will need to edit `etc/hadoop/core-site.xml` and `etc/hadoop/hdfs-site.xml` as follows:\n",
    "\n",
    "* `etc/hadoop/core-site.xml`:\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hdfs://localhost:9000</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "* `etc/hadoop/hdfs-site.xml`:\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>1</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "Hadoop distribution requires having preinstalled Java and knowing the root directory of it (Java 8 or 11 is required, more info [here](https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions)). \n",
    "A possible root directory of your already installed Java installation on Linux is \n",
    "\n",
    "```\n",
    " /usr/lib/jvm/default-java\n",
    "```\n",
    "\n",
    "Try making such path available through the `JAVA_HOME` environment variable. If Hadoop still can not pick it up, add it in the `etc/hadoop/hadoop-env.sh` file.\n",
    "\n",
    "It might be that by using `pdsh` you are required to set its authentication type to `ssh` by using `export PDSH_RCMD_TYPE=ssh` (more info [here](https://stackoverflow.com/questions/42756555/permission-denied-error-while-running-start-dfs-sh))\n",
    "\n",
    "Once you have formatted your filesystem (`$ bin/hdfs namenode -format`) and started the NameNode daemon (`$ sbin/start-dfs.sh`) you should be able to browse `http://localhost:9870/` and visualize the web interface of the daemon which should look similar to the following:\n",
    "\n",
    "<img src=\"https://bigdata2020exassets.blob.core.windows.net/ex03/hadoop.png\" width=\"1100\">\n",
    "\n",
    "In the `Datanodes` tab you should see a single operating datanode.\n",
    "\n",
    "### 4.1 &ndash; Upload a file into HDFS\n",
    "\n",
    "Pick an image file in your computer (or you can also download a random one) and try to upload it to HDFS. You may need to create an empty directory before uploading. (check [here](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html) for help)\n",
    "\n",
    "1. Which command do you use to upload from the local file system to HDFS?\n",
    "\n",
    "1. Which information can you find if you use `Utilities -> Browse the file system` in the daemon web interface?\n",
    "\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. It can be `\n",
    "```\n",
    "/bin/hadoop fs -mkdir /myfolder\n",
    "/bin/hadoop fs -put ~/Documents/image.JPG /myfolder\n",
    "```\n",
    "1. \n",
    "\n",
    "|Permission |\tOwner |\tGroup |\tSize |\tLast Modified |\tReplication |\tBlock Size\t| Name|\n",
    "|-----------|---------|-------|------|----------------|-------------|---------------|-----|\n",
    "|-rw-r--r--\t|anconam|\tsupergroup|\t3.61 MB|\t10/6/2016, 11:25:27 AM\t|1|\t128 MB\t|image.JPG|\n",
    "\n",
    "\n",
    "### 4.2 &ndash; Local File System\n",
    "\n",
    "Now take a look at the documented default values of `hdfs-default.xml` and `core-default.xml` and locate the file that you have just uploaded into HDFS.\n",
    "\n",
    "- http://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml\n",
    "- http://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/core-default.xml\n",
    "\n",
    "\n",
    "1. Is the image still accessible with a normal image viewer? \n",
    "\n",
    "1. What is the path of the image relative to the HDFS filesystem?\n",
    "\n",
    "1. What is the path of the image relative to your OS filesystem?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. Yes, it is still visible and readable.\n",
    "1. In my case it is `myfolder/image.JPG`.\n",
    "1. In my case it is `/tmp/hadoop-anconam/dfs/data/current/BP-92054669-127.0.1.1-1475745494816/current/finalized/subdir0/subdir0/blk_1073741825`.\n",
    "\n",
    "### 4.3 &ndash; Local File System\n",
    "\n",
    "Now try to upload a file that is ~150MB. On Unix-based system you can also generate such a file filled with zero using:\n",
    "\n",
    "```\n",
    "$ dd if=/dev/zero of=zeros.dat bs=1M count=150\n",
    "```\n",
    "\n",
    "1. How many blocks the file is split into?\n",
    "\n",
    "**Solution**\n",
    "1. Two, one of about 128MB and the other about 22MB.\n",
    "\n",
    "### 4.4 Stop HDFS\n",
    "\n",
    "Once you are done experimenting you can stop HDFS by running `$ sbin/stop-dfs.sh`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
